# Offense Predictor — How to Run (Windows / PowerShell)

This guide shows you how to run the **offense similarity predictor** locally, end‑to‑end: set up Python, build features from BigQuery, start the API, and query it.

> These steps assume the repo layout you’ve been using:
>
> ```text
> player-sim-gcp/
> ├── scripts/
> ├── data/
> ├── training/
> ├── service/
> ├── statistics/
> ├── artifacts/
> └── requirements.txt
> ```
>
> If any folder is missing, create it (e.g., `statistics/` and `artifacts/`).

---

## 0) Prerequisites

- **Python 3.10+** installed and on PATH (`python --version`).
- **gcloud + bq** CLI installed and authenticated (for BigQuery).
- A **GCP project** (e.g., `optimal-tea-470117-t4`) with BigQuery enabled.

### Create & activate a virtual environment (PowerShell)

```powershell
# In repo root
py -m venv .venv
.\.venv\Scripts\Activate.ps1

# Upgrade pip and install deps
python -m pip install --upgrade pip
pip install -r requirements.txt

# If uvicorn isn't in requirements.txt:
pip install uvicorn[standard]

# BigQuery client dependencies (if errors mention them):
pip install google-cloud-bigquery pandas db-dtypes
```
> To exit the venv later: `deactivate`

---

## 1) Prepare BigQuery (one-time)

If you **already** created and loaded these tables/views earlier, you can skip to step 2. Otherwise:

```powershell
# Set your project for client libraries (and login once)
$env:GOOGLE_CLOUD_PROJECT = "optimal-tea-470117-t4"
gcloud auth application-default login

# Create a dataset named "football"
bq mk --dataset football

# Load offense CSV (already generated by scripts/build_csvs_2018_2024.py)
bq load --autodetect --source_format=CSV --skip_leading_rows=1 `
  football.stats_offense .\statistics\stats_offense.csv
```

Create the **view** for per-game offense features (if not already created). You can either run the SQL in `data/create_views.sql` or inline the command:

```powershell
$views = @"
CREATE OR REPLACE VIEW football.features_offense AS
SELECT
  player_id,
  player_name,
  season,
  position,
  SAFE_DIVIDE(passing_yards, games)     AS passing_yards_pg,
  SAFE_DIVIDE(passing_tds, games)       AS passing_tds_pg,
  SAFE_DIVIDE(interceptions, games)     AS ints_pg,
  SAFE_DIVIDE(rushing_yards, games)     AS rushing_yards_pg,
  SAFE_DIVIDE(rushing_tds, games)       AS rushing_tds_pg,
  SAFE_DIVIDE(receiving_yards, games)   AS receiving_yards_pg
FROM football.stats_offense
WHERE games > 0;
"@

bq query --use_legacy_sql=false -q $views
```

Sanity check:
```powershell
bq ls football
bq query --use_legacy_sql=false -q "SELECT COUNT(*) AS rows FROM football.features_offense"
```

---

## 2) Build local features/artifacts (offense)

This pulls from the BigQuery view and writes the model artifacts used by the API.

```powershell
# Make sure GOOGLE_CLOUD_PROJECT is set and ADC is logged in (see step 1)
$env:GOOGLE_CLOUD_PROJECT = "optimal-tea-470117-t4"

# Run the feature builder
python .\training\prepare_features.py --mode offense
```

You should see files created at:
```
artifacts/offense/players.parquet
artifacts/offense/preproc.joblib
```

If you see `FAISS not available; using numpy at runtime`, that’s fine (it’s an optional speedup).

---

## 3) Start the API server

```powershell
# Tell the service where artifacts live (repo root)
$env:ARTIFACT_DIR = "$PWD\artifacts"

# Run the FastAPI app with Uvicorn
uvicorn service.main:app --reload --host 0.0.0.0 --port 8000
```

You should see Uvicorn logs saying it’s serving on `http://0.0.0.0:8000`.

---

## 4) Query the offense endpoint

### PowerShell (Invoke-WebRequest)
```powershell
Invoke-WebRequest -Uri "http://localhost:8000/similarity/offense" `
  -Method POST `
  -Headers @{ "Content-Type" = "application/json" } `
  -Body '{"passing_yards_pg":280,"passing_tds_pg":2.1,"ints_pg":0.7,"rushing_yards_pg":20,"rushing_tds_pg":0.1,"receiving_yards_pg":0,"k":5}' `
| Select-Object -ExpandProperty Content
```

### curl (Git Bash / WSL / macOS)
```bash
curl -s -X POST "http://localhost:8000/similarity/offense" \
  -H "Content-Type: application/json" \
  -d '{"passing_yards_pg":280,"passing_tds_pg":2.1,"ints_pg":0.7,"rushing_yards_pg":20,"rushing_tds_pg":0.1,"receiving_yards_pg":0,"k":5}'
```

Expected output:
```json
{
  "results": [
    {"player_id":"...","player_name":"...","season":2021,"position":"QB","similarity":0.998...},
    ...
  ]
}
```

---

## 5) Common issues & fixes

- **`ModuleNotFoundError: No module named 'google'`**  
  Install the BigQuery client packages in your venv:  
  `pip install google-cloud-bigquery db-dtypes`

- **`ProjectId must be non-empty`**  
  Set your project and login:  
  ```powershell
  $env:GOOGLE_CLOUD_PROJECT = "optimal-tea-470117-t4"
  gcloud auth application-default login
  ```

- **`BigQuery Storage module not found` (warning)**  
  Safe to ignore; it falls back to REST. If you want the faster path:  
  `pip install google-cloud-bigquery-storage`

- **`uvicorn : The term 'uvicorn' is not recognized`**  
  `pip install uvicorn[standard]` (inside the activated venv).

- **PowerShell redirection / heredoc quoting**  
  Prefer passing SQL via a variable (`$views = @" ... "@`) then `bq query -q $views`.

- **Artifacts missing**  
  Be sure to run `python .\training\prepare_features.py --mode offense` and verify files in `artifacts/offense/`.

---

## 6) Quick start (condensed)

```powershell
# In repo root
py -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install --upgrade pip
pip install -r requirements.txt uvicorn[standard] google-cloud-bigquery db-dtypes

$env:GOOGLE_CLOUD_PROJECT = "optimal-tea-470117-t4"
gcloud auth application-default login

# (If needed) create dataset & load CSV
bq mk --dataset football
bq load --autodetect --source_format=CSV --skip_leading_rows=1 `
  football.stats_offense .\statistics\stats_offense.csv

# (If needed) create the offense view
$views = @"
CREATE OR REPLACE VIEW football.features_offense AS
SELECT
  player_id, player_name, season, position,
  SAFE_DIVIDE(passing_yards, games)   AS passing_yards_pg,
  SAFE_DIVIDE(passing_tds, games)     AS passing_tds_pg,
  SAFE_DIVIDE(interceptions, games)   AS ints_pg,
  SAFE_DIVIDE(rushing_yards, games)   AS rushing_yards_pg,
  SAFE_DIVIDE(rushing_tds, games)     AS rushing_tds_pg,
  SAFE_DIVIDE(receiving_yards, games) AS receiving_yards_pg
FROM football.stats_offense
WHERE games > 0;
"@
bq query --use_legacy_sql=false -q $views

# Build artifacts
python .\training\prepare_features.py --mode offense

# Run API
$env:ARTIFACT_DIR = "$PWD\artifacts"
uvicorn service.main:app --reload --host 0.0.0.0 --port 8000

# Query
Invoke-WebRequest -Uri "http://localhost:8000/similarity/offense" `
  -Method POST `
  -Headers @{ "Content-Type" = "application/json" } `
  -Body '{"passing_yards_pg":280,"passing_tds_pg":2.1,"ints_pg":0.7,"rushing_yards_pg":20,"rushing_tds_pg":0.1,"receiving_yards_pg":0,"k":5}' `
| Select-Object -ExpandProperty Content
```

---

## 7) Where things land

- **BigQuery**: `football.stats_offense` (table), `football.features_offense` (view)
- **Artifacts**: `artifacts/offense/players.parquet`, `artifacts/offense/preproc.joblib`
- **Local API**: `http://localhost:8000/similarity/offense` (POST JSON)

If anything fails on your machine, copy the exact error and I’ll give a laser‑targeted fix.
